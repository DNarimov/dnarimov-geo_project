import streamlit as st
from pypdf import PdfReader
import pandas as pd
import math
import re
from openai import OpenAI
from io import BytesIO

# --- API ---
client = OpenAI(api_key=st.secrets["openai_api_key"])

# --- UI Localized Texts ---
ui_texts = {
    "page_title": {
        "ru": "ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð³ÐµÐ¾Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¸ÑÐ¿Ñ‹Ñ‚Ð°Ð½Ð¸Ð¹",
        "en": "Geotechnical Test Validator",
        "uz": "Geotexnik sinovlarni tekshirish"
    },
    "language_label": {
        "ru": "ðŸŒ Ð¯Ð·Ñ‹Ðº:", "en": "ðŸŒ Language:", "uz": "ðŸŒ Til:"
    },
    "upload_instruction": {
        "ru": "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ PDF Ð¸ Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ‚Ð¸Ð¿ Ð¸ÑÐ¿Ñ‹Ñ‚Ð°Ð½Ð¸Ñ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¿Ð¾ ASTM",
        "en": "Upload a PDF report and select a test type to validate against ASTM.",
        "uz": "PDF hisobotini yuklang va ASTM boâ€˜yicha tekshirish uchun sinov turini tanlang."
    },
    "comments_section": {
        "ru": "ðŸ’¬ ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸ Ð¾Ñ‚ Juru AI:",
        "en": "ðŸ’¬ Juru AI Comments:",
        "uz": "ðŸ’¬ Juru AI izohlari:"
    },
    "missing_notes": {
        "ru": "ðŸ“Œ Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð·Ð°Ð¼ÐµÑ‡Ð°Ð½Ð¸Ñ:",
        "en": "ðŸ“Œ Additional Notes:",
        "uz": "ðŸ“Œ Qoâ€˜shimcha eslatmalar:"
    },
    "missing_values": {
        "ru": "âš ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ:",
        "en": "âš ï¸ Missing values:",
        "uz": "âš ï¸ Yetishmayotgan qiymatlar:"
    },
    "all_present": {
        "ru": "âœ… Ð’ÑÐµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‚.",
        "en": "âœ… All values present.",
        "uz": "âœ… Barcha qiymatlar mavjud."
    },
    "download_excel": {
        "ru": "ðŸ“¥ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Excel",
        "en": "ðŸ“¥ Download Excel",
        "uz": "ðŸ“¥ Excel yuklab olish"
    },
    "upload_file": {
        "ru": "ðŸ“Ž Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ PDF Ð´Ð»Ñ",
        "en": "ðŸ“Ž Upload PDF for",
        "uz": "ðŸ“Ž Ushbu test uchun PDF yuklang:"
    },
    "loading_pdf": {
        "ru": "Ð§Ñ‚ÐµÐ½Ð¸Ðµ PDF...",
        "en": "Reading PDF...",
        "uz": "PDF oâ€˜qilmoqda..."
    },
    "pdf_loaded": {
        "ru": "âœ… PDF Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½.",
        "en": "âœ… PDF loaded.",
        "uz": "âœ… PDF yuklandi."
    }
}

# --- Language Selection ---
lang = st.sidebar.selectbox(
    ui_texts["language_label"]["en"],
    ["Ð ÑƒÑÑÐºÐ¸Ð¹", "English", "O'zbek"],
    key="language_selector"
)
lang_codes = {"Ð ÑƒÑÑÐºÐ¸Ð¹": "ru", "English": "en", "O'zbek": "uz"}
language_code = lang_codes[lang]

# --- Set page ---
st.set_page_config(ui_texts["page_title"][language_code], layout="wide")
st.title(ui_texts["page_title"][language_code])
st.markdown(ui_texts["upload_instruction"][language_code])

# --- ASTM Test Types ---
astm_standards = {
    "Electrical Resistivity Test (ERT)": "ASTM G57",
    "Seismic Refraction Test (SRT)": "ASTM D5777",
    "Atterberg Limit Test": "ASTM D4318",
    "Sieve Analysis": "ASTM D6913",
    "UCS Test - Soil": "ASTM D2166",
    "UCS Test - Rock": "ASTM D7012",
    "Oedometer Test": "ASTM D2435",
    "Direct Shear Test": "ASTM D3080",
    "Collapse Test": "ASTM D5333",
    "California Bearing Ratio": "ASTM D1883",
    "Proctor Test": "ASTM D698"
}
test_types = list(astm_standards.keys())

# --- Corrosion Configs ---
column_translations = {
    "ru": ["â„– Ð¿/Ð¿", "â„– Ð’Ñ‹Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸", "Ð Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¼ÐµÐ¶Ð´Ñƒ ÑÐ»ÐµÐºÑ‚Ñ€Ð¾Ð´Ð°Ð¼Ð¸ Ð°, (Ð¼)", "ÐŸÐ¾ÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¸Ð±Ð¾Ñ€Ð° R, (ÐžÐ¼)",
           "Ð£Ð´ÐµÐ»ÑŒÐ½Ð¾Ðµ ÑÐ»ÐµÐºÑ‚Ñ€Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ ÑÐ¾Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²Ð»ÐµÐ½Ð¸Ðµ Ï=2Ï€Ra ÐžÐ¼Â·Ð¼", "ÐšÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ð°Ñ Ð°Ð³Ñ€ÐµÑÑÐ¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ NACE",
           "ÐšÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ð°Ñ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ ASTM"],
    "en": ["No.", "Test Point", "Electrode Spacing a, (m)", "Instrument Reading R (Ohm)",
           "Resistivity Ï = 2Ï€Ra (OhmÂ·m)", "Corrosion Class (NACE)", "Corrosion Activity (ASTM)"],
    "uz": ["â„–", "Ish joyi", "Elektrodlar orasidagi masofa a, (m)", "Asbob ko'rsatkichi R (Om)",
           "Xususiy qarshilik Ï = 2Ï€Ra (OmÂ·m)", "Korroziya klassi (NACE)", "Korroziya faolligi (ASTM)"]
}

corrosion_labels = {
    "ru": {
        "ÐÐ¸Ð·ÐºÐ¾Ðµ": "ÐÐ¸Ð·ÐºÐ¾Ðµ", "Ð¡Ð»Ð°Ð±Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "Ð¡Ð»Ð°Ð±Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹", "Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹",
        "ÐšÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ð¾-Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹": "ÐšÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ð¾-Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹", "Ð’Ñ‹ÑÐ¾ÐºÐ¾ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "Ð’Ñ‹ÑÐ¾ÐºÐ¾ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹",
        "ÐžÑ‡ÐµÐ½ÑŒ ÑÐ»Ð°Ð±Ð°Ñ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ñ": "ÐžÑ‡ÐµÐ½ÑŒ ÑÐ»Ð°Ð±Ð°Ñ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ñ", "Ð§Ñ€ÐµÐ·Ð²Ñ‹Ñ‡Ð°Ð¹Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "Ð§Ñ€ÐµÐ·Ð²Ñ‹Ñ‡Ð°Ð¹Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹",
        "Out of range": "Ð’Ð½Ðµ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð°", "Invalid": "ÐÐµÐ´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾"
    },
    "en": {
        "ÐÐ¸Ð·ÐºÐ¾Ðµ": "Low", "Ð¡Ð»Ð°Ð±Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "Slightly Corrosive", "Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "Moderately Corrosive",
        "ÐšÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ð¾-Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹": "Corrosive", "Ð’Ñ‹ÑÐ¾ÐºÐ¾ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "Highly Corrosive",
        "ÐžÑ‡ÐµÐ½ÑŒ ÑÐ»Ð°Ð±Ð°Ñ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ñ": "Very Low", "Ð§Ñ€ÐµÐ·Ð²Ñ‹Ñ‡Ð°Ð¹Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "Severe",
        "Out of range": "Out of range", "Invalid": "Invalid"
    },
    "uz": {
        "ÐÐ¸Ð·ÐºÐ¾Ðµ": "Past", "Ð¡Ð»Ð°Ð±Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "Yengil korroziv", "Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "O'rtacha korroziv",
        "ÐšÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ð¾-Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹": "Faol korroziv", "Ð’Ñ‹ÑÐ¾ÐºÐ¾ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "Yuqori korroziv",
        "ÐžÑ‡ÐµÐ½ÑŒ ÑÐ»Ð°Ð±Ð°Ñ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ñ": "Juda past", "Ð§Ñ€ÐµÐ·Ð²Ñ‹Ñ‡Ð°Ð¹Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "Juda kuchli",
        "Out of range": "Tashqarida", "Invalid": "Notoâ€˜gâ€˜ri"
    }
}

corrosion_classes = [
    (100, float('inf'), "ÐÐ¸Ð·ÐºÐ¾Ðµ", "ÐžÑ‡ÐµÐ½ÑŒ ÑÐ»Ð°Ð±Ð°Ñ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ñ"),
    (50.01, 100, "Ð¡Ð»Ð°Ð±Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹", "Ð¡Ð»Ð°Ð±Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹"),
    (20.01, 50, "Ð¡Ð»Ð°Ð±Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹", "Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹"),
    (10.01, 20, "Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹", "Ð’Ñ‹ÑÐ¾ÐºÐ¾ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹"),
    (5.01, 10, "ÐšÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ð¾-Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹", "Ð§Ñ€ÐµÐ·Ð²Ñ‹Ñ‡Ð°Ð¹Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹"),
    (0, 5, "Ð’Ñ‹ÑÐ¾ÐºÐ¾ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹", "Ð§Ñ€ÐµÐ·Ð²Ñ‹Ñ‡Ð°Ð¹Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹"),
]

corrosion_colors = {
    "ÐÐ¸Ð·ÐºÐ¾Ðµ": "#d0f0c0", "ÐžÑ‡ÐµÐ½ÑŒ ÑÐ»Ð°Ð±Ð°Ñ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ñ": "#d0f0c0",
    "Ð¡Ð»Ð°Ð±Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "#fef3bd", "Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "#ffd59e",
    "ÐšÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ð¾-Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹": "#ffadad", "Ð’Ñ‹ÑÐ¾ÐºÐ¾ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "#ff6b6b",
    "Ð§Ñ€ÐµÐ·Ð²Ñ‹Ñ‡Ð°Ð¹Ð½Ð¾ ÐºÐ¾Ñ€Ñ€Ð¾Ð·Ð¸Ð¾Ð½Ð½Ñ‹Ð¹": "#ff6b6b", "Out of range": "#cccccc", "Invalid": "#e0e0e0"
}

missing_explanations = {
    "ru": {
        "R": "Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ R (Ð¿Ð¾ÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¸Ð±Ð¾Ñ€Ð°)",
        "Ï": "Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ ÑƒÐ´ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ ÑÐ¾Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²Ð»ÐµÐ½Ð¸Ñ, Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð° Ñ€Ð°ÑÑÑ‡Ð¸Ñ‚Ð°Ð»Ð° Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸"
    },
    "en": {
        "R": "missing value of R (instrument reading)",
        "Ï": "missing resistivity value, calculated automatically by the program"
    },
    "uz": {
        "R": "R qiymati yoâ€˜q (asbob koâ€˜rsatmasi)",
        "Ï": "Xususiy qarshilik yoâ€˜q, dastur tomonidan hisoblangan"
    }
}

# --- Utility Functions ---
def extract_text_from_pdf(pdf_file):
    reader = PdfReader(pdf_file)
    return "".join([page.extract_text() or "" for page in reader.pages])

def format_float(val):
    try:
        return f"{round(float(str(val).replace(',', '.')), 2):.2f}"
    except:
        return "-"

def parse_distance_to_meters(raw_value):
    val = raw_value.lower().strip().replace(",", ".")
    if "ÑÐ¼" in val or "cm" in val:
        numbers = re.findall(r"[\d.]+", val)
        if numbers:
            return round(float(numbers[0]) / 100, 4)
    try:
        fval = float(val)
        return round(fval / 100, 4) if fval > 10 else round(fval, 4)
    except:
        return None

def classify_corrosion(resistivity_ohm_m):
    try:
        val = float(resistivity_ohm_m)
        for low, high, nace, astm in corrosion_classes:
            if low <= val <= high:
                return nace, astm
        return "Out of range", "Out of range"
    except:
        return "Invalid", "Invalid"

def ask_gpt_astm_analysis(test_name, extracted_text, model_name, language_code):
    prompt = f"""
You are an expert geotechnical assistant. Analyze the report below.
1. Extract only relevant data rows for the test: \"{test_name}\".
2. Create a clean markdown table with 7 columns:
| â„– | Ð¢Ð¾Ñ‡ÐºÐ° | a (Ð¼) | R (ÐžÐ¼) | Ï (ÐžÐ¼Â·Ð¼) | NACE | ASTM |
3. Use '-' if a cell is empty.
4. Do not explain anything outside the table.
5. After the table, in plain text, list:
   - Missing R values
   - Auto-calculated Ï = 2Ï€Ra values
Language: {language_code.upper()}
"""{extracted_text}"""
"""
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=2000
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ GPT error: {e}"

def gpt_response_to_table(response, lang_code):
    lines = [line for line in response.splitlines() if line.strip().startswith("|") and "---" not in line]
    data = []
    for line in lines:
        parts = [p.strip() for p in line.strip("| \n").split("|")]
        if len(parts) < 5:
            continue
        number, point, a_raw, r_raw, rho_raw = parts[:5]
        a_val = parse_distance_to_meters(a_raw)
        a = format_float(a_val) if a_val else "-"
        try: r_float = float(r_raw.replace(",", ".")) if r_raw != "-" else None
        except: r_float = None
        try: rho_float = float(rho_raw.replace(",", ".")) if rho_raw != "-" else None
        except: rho_float = None
        if (not rho_float or rho_float < 1) and r_float and a_val:
            rho_calc = 2 * math.pi * r_float * a_val
            rho = format_float(rho_calc)
        else:
            rho = format_float(rho_float)
        nace, astm = classify_corrosion(rho)
        nace = corrosion_labels[lang_code].get(nace, nace)
        astm = corrosion_labels[lang_code].get(astm, astm)
        data.append([number, point, a, format_float(r_raw), rho, nace, astm])
    return pd.DataFrame(data, columns=column_translations[lang_code])

def style_table(df):
    def color(val): return f"background-color: {corrosion_colors.get(val, '')}"
    def highlight(val): return "background-color: #fdd" if val in ["-", "nan", "", None] else ""
    return df.style.applymap(color, subset=[df.columns[-2], df.columns[-1]]).applymap(highlight)

def explain_missing_values(df, lang_code):
    messages = []
    for idx, row in df.iterrows():
        well = row[1]
        r = str(row[3]).strip().lower()
        rho = str(row[4]).strip().lower()
        if r in ["-", "", "nan", "none"]:
            messages.append(f"{well} â€“ {missing_explanations[lang_code]['R']}")
        if rho in ["-", "", "nan", "none"]:
            messages.append(f"{well} â€“ {missing_explanations[lang_code]['Ï']}")
    return messages

# --- Main Loop ---
for i, test_name in enumerate(test_types):
    with tabs[i]:
        st.header(test_name)
        uploaded_file = st.file_uploader(f"{ui_texts['upload_file'][language_code]} {test_name}", type="pdf", key=f"file_{test_name}")
        if uploaded_file:
            with st.spinner(ui_texts["loading_pdf"][language_code]):
                text = extract_text_from_pdf(uploaded_file)
                st.success(ui_texts["pdf_loaded"][language_code])
            gpt_response = ask_gpt_astm_analysis(test_name, text, model_choice, language_code)
            df_result = gpt_response_to_table(gpt_response, language_code)
            st.dataframe(style_table(df_result), use_container_width=True)
            missing_notes = explain_missing_values(df_result, language_code)
            if missing_notes:
                st.subheader(ui_texts["missing_notes"][language_code])
                for note in missing_notes:
                    st.markdown(f"- {note}")
            missing = []
            for row in df_result.itertuples(index=False):
                for j, val in enumerate(row):
                    if str(val).strip().lower() in ["-", "nan", "", "none"]:
                        missing.append(f"âŒ {df_result.columns[j]}: ÑÑ‚Ñ€Ð¾ÐºÐ° {row[0]}")
            if missing:
                st.subheader(ui_texts["missing_values"][language_code])
                for m in missing:
                    st.markdown(f"- {m}")
            else:
                st.success(ui_texts["all_present"][language_code])
            comments = [l for l in gpt_response.splitlines() if "|" not in l and "---" not in l and l.strip()]
            if comments:
                st.subheader(ui_texts["comments_section"][language_code])
                for c in comments:
                    st.markdown(f"- {c}")
            excel_buffer = BytesIO()
            with pd.ExcelWriter(excel_buffer, engine="xlsxwriter") as writer:
                df_result.to_excel(writer, index=False, sheet_name="GPT Analysis")
            st.download_button(ui_texts["download_excel"][language_code], data=excel_buffer.getvalue(), file_name=f"{test_name}.xlsx")


def gpt_response_to_table(response, lang_code):
    lines = [line for line in response.splitlines() if line.strip().startswith("|") and "---" not in line]
    data = []

    for line in lines:
        parts = [p.strip() for p in line.strip("| \n").split("|")]
        if len(parts) < 5:
            continue

        number, point, a_raw, r_raw, rho_raw = parts[:5]

        a_val = parse_distance_to_meters(a_raw)
        a = format_float(a_val) if a_val else "-"

        try: r_float = float(r_raw.replace(",", ".")) if r_raw != "-" else None
        except: r_float = None

        try: rho_float = float(rho_raw.replace(",", ".")) if rho_raw != "-" else None
        except: rho_float = None

        if (not rho_float or rho_float < 1) and r_float and a_val:
            rho_calc = 2 * math.pi * r_float * a_val
            rho = format_float(rho_calc)
        else:
            rho = format_float(rho_float)

        nace, astm = classify_corrosion(rho)
        nace = corrosion_labels[lang_code].get(nace, nace)
        astm = corrosion_labels[lang_code].get(astm, astm)

        data.append([
            number, point, a, format_float(r_raw), rho, nace, astm
        ])

    return pd.DataFrame(data, columns=column_translations[lang_code])


def gpt_response_to_table(response, lang_code):
    lines = [line for line in response.splitlines() if "|" in line and "â„–" not in line and "---" not in line]
    data = []
    for line in lines:
        parts = [p.strip() for p in line.strip("- ").split("|") if p.strip()]
        if len(parts) < 5:
            continue
        number, well_no, a_raw, r_val, rho_val = parts[:5]
        a_m = parse_distance_to_meters(a_raw)
        a_val = format_float(a_m) if a_m else "-"
        try: r_float = float(r_val.replace(",", ".")) if r_val != "-" else None
        except: r_float = None
        try: rho_float = float(rho_val.replace(",", ".")) if rho_val != "-" else None
        except: rho_float = None
        if (rho_float is None or rho_float < 20) and r_float and a_m:
            rho_val = format_float(2 * math.pi * r_float * a_m)
        else:
            rho_val = format_float(rho_float)
        nace, astm = classify_corrosion(rho_val)
        nace = corrosion_labels[lang_code].get(nace, nace)
        astm = corrosion_labels[lang_code].get(astm, astm)
        data.append([number, well_no, a_val, format_float(r_val), rho_val, nace, astm])
    return pd.DataFrame(data, columns=column_translations[lang_code])

def style_table(df):
    def color(val): return f"background-color: {corrosion_colors.get(val, '')}"
    def highlight(val): return "background-color: #fdd" if val in ["-", "nan", "", None] else ""
    return df.style.applymap(color, subset=[df.columns[-2], df.columns[-1]]).applymap(highlight)

def explain_missing_values(df, lang_code):
    messages = []
    for idx, row in df.iterrows():
        well = row[1]
        r = str(row[3]).strip().lower()
        rho = str(row[4]).strip().lower()
        if r in ["-", "", "nan", "none"]:
            messages.append(f"{well} â€“ {missing_explanations[lang_code]['R']}")
        if rho in ["-", "", "nan", "none"]:
            messages.append(f"{well} â€“ {missing_explanations[lang_code]['Ï']}")
    return messages

# --- Tabs per Test ---
model_choice = st.sidebar.selectbox("ðŸ¤– Juru AI Model:", ["gpt-4-turbo", "gpt-3.5-turbo"], key="model_selector")
tabs = st.tabs(test_types)

for i, test_name in enumerate(test_types):
    with tabs[i]:
        st.header(test_name)
        uploaded_file = st.file_uploader(f"{ui_texts['upload_file'][language_code]} {test_name}", type="pdf", key=f"file_{test_name}")

        if uploaded_file:
            with st.spinner(ui_texts["loading_pdf"][language_code]):
                text = extract_text_from_pdf(uploaded_file)
                st.success(ui_texts["pdf_loaded"][language_code])

            gpt_response = ask_gpt_astm_analysis(test_name, text, model_choice, language_code)
            df_result = gpt_response_to_table(gpt_response, language_code)
            st.dataframe(style_table(df_result), use_container_width=True)

            missing_notes = explain_missing_values(df_result, language_code)
            if missing_notes:
                st.subheader(ui_texts["missing_notes"][language_code])
                for note in missing_notes:
                    st.markdown(f"- {note}")

            missing = []
            for row in df_result.itertuples(index=False):
                for j, val in enumerate(row):
                    if str(val).strip().lower() in ["-", "nan", "", "none"]:
                        missing.append(f"âŒ {df_result.columns[j]}: ÑÑ‚Ñ€Ð¾ÐºÐ° {row[0]}")

            if missing:
                st.subheader(ui_texts["missing_values"][language_code])
                for m in missing:
                    st.markdown(f"- {m}")
            else:
                st.success(ui_texts["all_present"][language_code])

            comments = [l for l in gpt_response.splitlines() if "|" not in l and "---" not in l and l.strip()]
            if comments:
                st.subheader(ui_texts["comments_section"][language_code])
                for c in comments:
                    st.markdown(f"- {c}")

            excel_buffer = BytesIO()
            with pd.ExcelWriter(excel_buffer, engine="xlsxwriter") as writer:
                df_result.to_excel(writer, index=False, sheet_name="GPT Analysis")
            st.download_button(ui_texts["download_excel"][language_code], data=excel_buffer.getvalue(), file_name=f"{test_name}.xlsx")
